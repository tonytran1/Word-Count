Tony Tran
December 12th, 2016
Are ‘you’ even conscious?
INTRODUCTION: 
The Turing Test: established by one of the greatest thinkers of all time, Alan Turing, is an intelligence evaluation which asks a simple question: Are we able to differentiate between an entity (normally artificial intelligence) and a typical human being by communicating with it? If we are not able to find an indistinguishable difference, then the entity passes Turing’s test. It may be worth noting that it should not to be confused with Turing Machines, which is a tool for evaluating what computations are possible. However, there is a fine relationship between what is ‘possible’ computationally and what humans can create artificially.
THESIS / QUESTIONS: 
Hypothetically, let us assume that an entity has passed the Turing Test. We have no idea what this mysterious entity is, but we do know that it has succeeded in being indistinguishable from a typical human being. There are many questions that arise from this result, but I feel that some of the most important questions to be asked are: Does this entity have the ability to think for itself or has it been preprogrammed to listen to certain stimuli and respond accordingly? How is that any different from a human? More precisely, does this entity have decision making capabilities that rival a typical human - is it conscious? How do we even agree on what a typical human being is or how they ‘should’ think? Are humans too subjective/emotional for this test to even be valid? 
SUPPORT / MORE QUESTIONS: 
There are many nuances in the way humans think and perform that differentiate from other humans, therefore we would first have to agree on what is typical. Interestingly, humans differ so much in their reasoning that it is quite impossible to even assume that every human itself can pass the Turing Test. We have those with hidden mental variances and many with different upbringings and cultures that it is hard to agree on what is typical. However, let us then assume that we have a ‘testable formula’ on what a typical human is. Typical humans have an incredible amount of intuition that allows us to make decisions and thoughts based on very little input. This intuition can be considered the key difference between current artificial intelligence and humans. Personally, I believe Alan Turing gave way to the belief that if it were actually possible to program an ‘entity’ that is indistinguishable from a human being, we would then have to assume that humans are in itself some type of a ‘machine’ that also does computations to arrive at their outputs/conclusions. If we can somehow ‘prove’ that this entity encounters these intuitions, then I would hop on board to agree that this ‘entity’ is ‘conscious enough’ and not just acting ‘conscious’. However, since humans have yet to fully understand the deep underlying workings of consciousness, how can we even say that something is something when we don’t know what that something truly is? Even so, suppose ‘all humans’ agree on a certain belief of consciousness, how can we prove that it is actually true and not just some fabricated subjective view from itself?
